{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-27T00:26:57.776920Z",
     "start_time": "2025-03-27T00:26:56.974205Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from datasets import PolynomialDataset\n",
    "from models import VAE\n",
    "\n",
    "dataset = PolynomialDataset(\"Click_details\", \"Train_details\", transform=MinMaxScaler())\n",
    "features = dataset.features.iloc.values \n",
    "dataset_feature = torch.tensor(features, dtype=torch.float32)\n",
    "dataloader = DataLoader(dataset_feature, batch_size=32, shuffle=True)\n",
    "\n",
    "input_dim = features.shape[1]\n",
    "latent_dim = 5\n",
    "vae = VAE(input_dim, latent_dim)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 50\n",
    "vae.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "        decoded, mu, logvar, _ = vae(batch)\n",
    "        loss_recon = criterion(decoded, batch)\n",
    "        loss_kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = loss_recon + 0.1 * loss_kl  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "vae.eval()\n",
    "latent_vectors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader, desc=\"Extracting latent vectors\"):\n",
    "        _, _, _, z = vae(batch)\n",
    "        latent_vectors.append(z.numpy())\n",
    "latent_vectors = np.vstack(latent_vectors)\n",
    "\n",
    "num_clusters = 3  \n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(latent_vectors)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "df_clusters = dataset.features.copy()\n",
    "df_clusters[\"Cluster\"] = labels\n",
    "print(df_clusters.head())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
