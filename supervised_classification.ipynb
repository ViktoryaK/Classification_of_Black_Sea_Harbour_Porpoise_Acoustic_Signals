{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "ef41e34419390471"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-28T13:20:04.952584Z",
     "start_time": "2025-04-28T13:20:04.925079Z"
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, auc, roc_auc_score, classification_report, confusion_matrix\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import zipfile\n",
    "import gdown\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import TestDataset\n",
    "from utils import apply_smote, find_knn_per_class\n"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'find_knn_per_class' from 'utils' (C:\\Users\\Admin\\Documents\\Classification_of_Black_Sea_Harbour_Porpoise_Acoustic_Signals\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodel_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TestDataset\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m apply_smote, find_knn_per_class\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'find_knn_per_class' from 'utils' (C:\\Users\\Admin\\Documents\\Classification_of_Black_Sea_Harbour_Porpoise_Acoustic_Signals\\utils.py)"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading and preprocessing",
   "id": "f5c916a4e40743e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T13:20:46.654508Z",
     "start_time": "2025-04-28T13:20:37.019595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = TestDataset(\"data_files/new click trains (Bulgaria)\")\n",
    "test_x, test_y, test_meta = dataset.get_labeled()\n",
    "\n",
    "print(f\"Test samples: {len(test_x)}\")\n",
    "data = np.load(\"data_files/full_acoustic_dataset.npz\", allow_pickle=True)\n",
    "labeled_x = data['labeled_x']\n",
    "labeled_y = data['labeled_y']\n",
    "unlabeled_x = data['unlabeled_x']\n",
    "unlabeled_meta = data['unlabeled_meta']\n",
    "labeled_meta = data['labeled_meta']\n",
    "\n",
    "labeled = np.concatenate((labeled_y, test_y), axis=0)\n",
    "distribution = Counter(labeled)\n",
    "total = len(labeled)\n",
    "print(\"\\nTest Distribution:\")\n",
    "for label, count in distribution.items():\n",
    "    pct = (count / total) * 100\n",
    "    print(f\"Class {label}: {count} ({pct:.2f}%)\")"
   ],
   "id": "59be4c9de0134eff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 64\n",
      "\n",
      "Test Distribution:\n",
      "Class 0: 195 (34.51%)\n",
      "Class 1: 370 (65.49%)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Upsampling",
   "id": "653a10e3679648cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n_to_add_per_class = 3000\n",
    "\n",
    "all_new_x = []\n",
    "all_new_y = []\n",
    "for cls in np.unique(labeled_y):\n",
    "    results, new_x, new_y, unlabeled_x, unlabeled_meta = find_knn_per_class(\n",
    "        labeled_x, labeled_y,\n",
    "        unlabeled_x, unlabeled_meta,\n",
    "        target_class=cls,\n",
    "        n_to_add=n_to_add_per_class - len(labeled_y[np.where(labeled_y == cls)]), \n",
    "        distance_threshold=2000\n",
    "    )\n",
    "    print(f\"Class {cls}: added {len(new_y)} new samples.\")\n",
    "    all_new_x.append(new_x)\n",
    "    all_new_y.append(new_y)\n",
    "\n",
    "pseudo_x = np.vstack(all_new_x)\n",
    "pseudo_y = np.concatenate(all_new_y)\n",
    "\n",
    "print(\"Final up-sampled size:\", pseudo_x.shape)\n",
    "print(\"Remaining unlabeled:\", unlabeled_x.shape)\n",
    "\n",
    "# === Combine and apply SMOTE ===\n",
    "X_resampled = np.concatenate([labeled_x, pseudo_x])\n",
    "y_resampled = np.concatenate([labeled_y, pseudo_y])\n",
    "\n",
    "print(\"Original class distribution:\", Counter(y_resampled))\n",
    "X_resampled, y_resampled = apply_smote(X_resampled, y_resampled)\n",
    "print(\"Resampled class distribution:\", Counter(y_resampled))"
   ],
   "id": "b268b62791ebc3b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data preprocessing",
   "id": "d5ecbc63d1029cb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scaler = StandardScaler()\n",
    "X_all = scaler.fit_transform(X_resampled)\n",
    "test_x = scaler.transform(test_x)\n",
    "indices = np.arange(X_all.shape[0])\n",
    "rng = np.random.default_rng(seed=42) \n",
    "rng.shuffle(indices)\n",
    "\n",
    "X_all = X_all[indices]\n",
    "y_all = y_resampled[indices]\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(X_all, y_all, test_size=0.3, random_state=42)\n",
    "\n",
    "class0_indices = np.where(test_y == 0)[0]\n",
    "class1_indices = np.where(test_y == 1)[0]\n",
    "\n",
    "np.random.seed(42)\n",
    "selected_class1_indices = np.random.choice(class1_indices, size=len(class0_indices), replace=False)\n",
    "\n",
    "balanced_indices = np.concatenate([class0_indices, selected_class1_indices])\n",
    "np.random.shuffle(balanced_indices)\n",
    "\n",
    "test_x = test_x[balanced_indices]\n",
    "test_y = test_y[balanced_indices]\n",
    "test_meta = test_meta[balanced_indices]\n",
    "\n",
    "distribution = Counter(train_y)\n",
    "total = len(train_y)\n",
    "print(\"\\nTrain Distribution:\")\n",
    "for label, count in distribution.items():\n",
    "    pct = (count / total) * 100\n",
    "    print(f\"Class {label}: {count} ({pct:.2f}%)\")\n",
    "    \n",
    "distribution = Counter(val_y)\n",
    "total = len(val_y)\n",
    "print(\"\\nValidation Distribution:\")\n",
    "for label, count in distribution.items():\n",
    "    pct = (count / total) * 100\n",
    "    print(f\"Class {label}: {count} ({pct:.2f}%)\")\n",
    "    \n",
    "distribution = Counter(test_y)\n",
    "total = len(test_y)\n",
    "print(\"\\nTest Distribution:\")\n",
    "for label, count in distribution.items():\n",
    "    pct = (count / total) * 100\n",
    "    print(f\"Class {label}: {count} ({pct:.2f}%)\")\n",
    "    "
   ],
   "id": "b8e37d9333f14859"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Models training\n",
    "\n",
    "## Random Forest"
   ],
   "id": "717ce66b8db1b6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced',\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(train_x, train_y)\n",
    "\n",
    "probs = rf_model.predict_proba(test_x)\n",
    "preds = rf_model.predict(test_x)\n",
    "\n",
    "print(\"Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(test_y, preds):.4f}\")\n",
    "print(f\"F1 Score (macro): {f1_score(test_y, preds, average='macro'):.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_score(test_y, preds, average='weighted'):.4f}\")\n",
    "print(\"\\nPer-Class Classification Report:\")\n",
    "print(classification_report(test_y, preds, digits=4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, preds))"
   ],
   "id": "7aca99c073ad52eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## XGBoost",
   "id": "e340bf2f94fa440b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.005,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss',\n",
    ")\n",
    "\n",
    "xgb_model.fit(train_x, train_y)\n",
    "\n",
    "probs = xgb_model.predict_proba(test_x)\n",
    "preds = xgb_model.predict(test_x)\n",
    "\n",
    "print(\"Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(test_y, preds):.4f}\")\n",
    "print(f\"F1 Score (macro): {f1_score(test_y, preds, average='macro'):.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_score(test_y, preds, average='weighted'):.4f}\")\n",
    "print(\"\\nPer-Class Classification Report:\")\n",
    "print(classification_report(test_y, preds, digits=4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, preds))"
   ],
   "id": "a75c6d6a09e6919c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3682cbea47034c51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Torch + CUDA)",
   "language": "python",
   "name": "mytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
