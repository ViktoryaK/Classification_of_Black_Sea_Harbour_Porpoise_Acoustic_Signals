{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reqirements",
   "id": "cafd57f962978134"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T18:46:31.230438Z",
     "start_time": "2025-05-01T18:46:27.696207Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -r requirements.txt",
   "id": "d85845f12526e7b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy~=1.26.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn~=1.6.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 2)) (1.6.1)\n",
      "Requirement already satisfied: torch~=2.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 3)) (2.7.0)\n",
      "Requirement already satisfied: matplotlib~=3.9.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 4)) (3.9.2)\n",
      "Requirement already satisfied: tqdm~=4.67.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: xgboost~=3.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: gdown~=5.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 8)) (5.2.0)\n",
      "Requirement already satisfied: imbalanced-learn~=0.13.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 9)) (0.13.0)\n",
      "Requirement already satisfied: pandas~=2.2.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 10)) (2.2.3)\n",
      "Requirement already satisfied: umap-learn~=0.5.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 11)) (0.5.7)\n",
      "Requirement already satisfied: fastdtw~=0.3.4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 12)) (0.3.4)\n",
      "Requirement already satisfied: scipy~=1.15.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 13)) (1.15.1)\n",
      "Requirement already satisfied: shap~=0.47.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 14)) (0.47.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn~=1.6.1->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch~=2.7.0->-r requirements.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch~=2.7.0->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch~=2.7.0->-r requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch~=2.7.0->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch~=2.7.0->-r requirements.txt (line 3)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch~=2.7.0->-r requirements.txt (line 3)) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch~=2.7.0->-r requirements.txt (line 3)) (75.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.9.2->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.9.2->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.9.2->-r requirements.txt (line 4)) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.9.2->-r requirements.txt (line 4)) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.9.2->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.9.2->-r requirements.txt (line 4)) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.9.2->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib~=3.9.2->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm~=4.67.1->-r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown~=5.2.0->-r requirements.txt (line 8)) (4.12.3)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown~=5.2.0->-r requirements.txt (line 8)) (2.32.3)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn~=0.13.0->-r requirements.txt (line 9)) (0.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas~=2.2.3->-r requirements.txt (line 10)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas~=2.2.3->-r requirements.txt (line 10)) (2024.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from umap-learn~=0.5.7->-r requirements.txt (line 11)) (0.61.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from umap-learn~=0.5.7->-r requirements.txt (line 11)) (0.5.13)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap~=0.47.2->-r requirements.txt (line 14)) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from shap~=0.47.2->-r requirements.txt (line 14)) (3.1.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from numba>=0.51.2->umap-learn~=0.5.7->-r requirements.txt (line 11)) (0.44.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.9.2->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch~=2.7.0->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->gdown~=5.2.0->-r requirements.txt (line 8)) (2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch~=2.7.0->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown~=5.2.0->-r requirements.txt (line 8)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown~=5.2.0->-r requirements.txt (line 8)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown~=5.2.0->-r requirements.txt (line 8)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown~=5.2.0->-r requirements.txt (line 8)) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown~=5.2.0->-r requirements.txt (line 8)) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "232a0fbaae0d428b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-01T18:46:35.160246Z",
     "start_time": "2025-05-01T18:46:31.241228Z"
    }
   },
   "source": [
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "from models import predict_ae, predict_proba_ae\n",
    "from datasets import AcousticDataset\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from collections import Counter, defaultdict\n",
    "from models import AutoencoderClassifier"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data and model loading",
   "id": "f7aedeb5508e37c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T18:46:35.537253Z",
     "start_time": "2025-05-01T18:46:35.312248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = joblib.load(\"save/scaler.pkl\")\n",
    "train_dataset = AcousticDataset(\n",
    "    \"Train_details/B Balchik 2020 11 14 FPOD_6288 file0 PART 79d 23h 19m train details\")\n",
    "\n",
    "unlabeled_x, unlabeled_meta = train_dataset.get_unlabeled()\n",
    "model = AutoencoderClassifier(unlabeled_x.shape[1], dropout_rate=0.2).to(device)\n",
    "model.load_state_dict(torch.load(\"save/final_ae_model.pth\"))\n",
    "model.eval()\n"
   ],
   "id": "c1445ed6d32d8e11",
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001B[1mdo those steps only if you trust the source of the checkpoint\u001B[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL models.AutoencoderClassifier was not an allowed global by default. Please use `torch.serialization.add_safe_globals([models.AutoencoderClassifier])` or the `torch.serialization.safe_globals([models.AutoencoderClassifier])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnpicklingError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfinal_ae_model.pth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m      3\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1524\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1516\u001B[0m                 \u001B[38;5;28;01mreturn\u001B[39;00m _load(\n\u001B[0;32m   1517\u001B[0m                     opened_zipfile,\n\u001B[0;32m   1518\u001B[0m                     map_location,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1521\u001B[0m                     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args,\n\u001B[0;32m   1522\u001B[0m                 )\n\u001B[0;32m   1523\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1524\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(_get_wo_message(\u001B[38;5;28mstr\u001B[39m(e))) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(\n\u001B[0;32m   1526\u001B[0m             opened_zipfile,\n\u001B[0;32m   1527\u001B[0m             map_location,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1530\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args,\n\u001B[0;32m   1531\u001B[0m         )\n\u001B[0;32m   1532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n",
      "\u001B[1;31mUnpicklingError\u001B[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001B[1mdo those steps only if you trust the source of the checkpoint\u001B[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL models.AutoencoderClassifier was not an allowed global by default. Please use `torch.serialization.add_safe_globals([models.AutoencoderClassifier])` or the `torch.serialization.safe_globals([models.AutoencoderClassifier])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Filtering\n",
    "\n",
    "Filters the unlabeled data using the Isolation Forest, to keep only the entries which are promising to belong to one of the classes."
   ],
   "id": "d79b2ecc935728ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define feature columns to be used for filtering unlabeled data.\n",
    "FEATURE_COLUMNS = [\n",
    "    'ClksThisMin', 'medianKHz', 'avSPL', 'avPkAt',\n",
    "    'AvPRF', 'avEndF', 'tWUTrisk', 'nActualClx', 'nRisingIPIs',\n",
    "    'TrDur_us', 'nICIrising', 'MinICI_us', 'midpointICI', 'MaxICI_us',\n",
    "    'ClkNofMinICI', 'ClkNofMaxICI', 'NofClstrs', 'avClstrNx8', 'avPkIPI',\n",
    "    'BeforeIPIratio', 'PreIPIratio', 'Post1IPIratio', 'Post2IPIratio', 'EndIPIratio'\n",
    "]\n",
    "\n",
    "def filter_unlabeled_with_isolation_forest(unlabeled_features, unlabeled_meta, contamination=0.08, random_state=42):\n",
    "    \"\"\"\n",
    "    Filters out likely outliers from unlabeled data using Isolation Forest.\n",
    "\n",
    "    Args:\n",
    "        unlabeled_features (np.ndarray): Unlabeled feature matrix (samples x features).\n",
    "        unlabeled_meta (np.ndarray): Corresponding metadata for each sample.\n",
    "        contamination (float): Expected proportion of outliers in the data.\n",
    "        random_state (int): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: Filtered feature array and corresponding metadata.\n",
    "    \"\"\"\n",
    "    iso_forest = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "    outlier_flags = iso_forest.fit_predict(unlabeled_features)\n",
    "\n",
    "    # Keep only samples predicted as outliers (-1)\n",
    "    is_outlier = outlier_flags == -1\n",
    "    filtered_features = unlabeled_features[is_outlier]\n",
    "    filtered_meta = unlabeled_meta[is_outlier]\n",
    "\n",
    "    return filtered_features, filtered_meta\n",
    "\n",
    "filtered_unlabeled, filtered_meta = filter_unlabeled_with_isolation_forest(unlabeled_x, unlabeled_meta)"
   ],
   "id": "34fccc58b0aa88e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Classification\n",
    "\n",
    "Applies the trained classification."
   ],
   "id": "395fd226fa11ee31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === Predict on full unlabeled set ===\n",
    "filtered_unlabeled = scaler.transform(filtered_unlabeled)\n",
    "unlabeled_probs = predict_proba_ae(model, filtered_unlabeled, device=device)\n",
    "unlabeled_preds = predict_ae(model, filtered_unlabeled, device=device)\n",
    "\n",
    "confidence_threshold = 0.95\n",
    "\n",
    "# Generate final predictions and mask for confident samples\n",
    "final_unlabeled_preds = []\n",
    "final_unlabeled_meta = []\n",
    "for pred, prob, meta in zip(unlabeled_preds, unlabeled_probs, filtered_meta):\n",
    "    if max(prob) >= confidence_threshold:\n",
    "        final_unlabeled_preds.append(pred)\n",
    "        final_unlabeled_meta.append(meta)\n",
    "    else:\n",
    "        final_unlabeled_preds.append(2)  # Assign to class 2 (noise)\n",
    "        final_unlabeled_meta.append(meta)\n",
    "\n",
    "final_unlabeled_preds = np.array(final_unlabeled_preds)\n",
    "final_unlabeled_meta = np.array(final_unlabeled_meta)\n",
    "\n",
    "# === Print stats ===\n",
    "distribution = Counter(final_unlabeled_preds)\n",
    "total = len(final_unlabeled_preds)\n",
    "print(\"\\nFinal Unlabeled Predictions Distribution:\")\n",
    "for label, count in distribution.items():\n",
    "    pct = (count / total) * 100\n",
    "    print(f\"Class {label}: {count} ({pct:.2f}%)\")\n",
    "print(len(final_unlabeled_preds), len(final_unlabeled_meta))"
   ],
   "id": "fb9f8036dec03f64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Postprocessing\n",
    "\n",
    "Applies the time-based grouping for entries of class 1."
   ],
   "id": "61ba91cddaa549f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def postprocess_class1_sequences(unlabeled_x, unlabeled_y, unlabeled_meta, time_gap_threshold_us=15_000_000):\n",
    "    \"\"\"\n",
    "    Postprocess predicted class 1 (communication) sequences by checking temporal continuity.\n",
    "\n",
    "    This function groups signals by location and ensures that only sequences of class 1 instances\n",
    "    with short temporal gaps are kept as class 1. Isolated class 1 instances are relabeled as class 2 (noise).\n",
    "\n",
    "    Args:\n",
    "        unlabeled_x (np.ndarray): Unlabeled feature array (samples x features).\n",
    "        unlabeled_y (np.ndarray): Predicted class labels (0, 1, or 2) for the samples.\n",
    "        unlabeled_meta (np.ndarray): Metadata for each sample, expected to include\n",
    "                                     (Location, Minute, Microseconds).\n",
    "        time_gap_threshold_us (int): Maximum time gap (in microseconds) allowed between\n",
    "                                     consecutive class 1 samples to consider them part of a sequence.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Updated labels where short/isolated class 1 samples are reassigned to class 2.\n",
    "    \"\"\"\n",
    "    # List of feature column names and the index of the 'TrDur_us' (duration) column\n",
    "    feature_column_names = [\n",
    "        'ClksThisMin', 'medianKHz', 'avSPL', 'avPkAt',\n",
    "        'AvPRF', 'avEndF', 'tWUTrisk', 'nActualClx', 'nRisingIPIs',\n",
    "        'TrDur_us', 'nICIrising', 'MinICI_us', 'midpointICI', 'MaxICI_us',\n",
    "        'ClkNofMinICI', 'ClkNofMaxICI', 'NofClstrs', 'avClstrNx8', 'avPkIPI',\n",
    "        'BeforeIPIratio', 'PreIPIratio', 'Post1IPIratio', 'Post2IPIratio', 'EndIPIratio'\n",
    "    ]\n",
    "    trdur_idx = feature_column_names.index('TrDur_us')\n",
    "\n",
    "    # Group samples by location, mapping each to a list of (start_time, end_time, index)\n",
    "    data_by_location = defaultdict(list)\n",
    "    for idx, meta in enumerate(unlabeled_meta):\n",
    "        location, minute_str, micro_str = meta\n",
    "        start_us = np.int64(int(minute_str)) * 60 * 1_000_000 + np.int64(int(micro_str))\n",
    "        duration_us = np.int64(unlabeled_x[idx, trdur_idx])\n",
    "        end_us = start_us + duration_us\n",
    "        data_by_location[location].append((start_us, end_us, idx))\n",
    "\n",
    "    # Sort each location's entries by time\n",
    "    for loc in data_by_location:\n",
    "        data_by_location[loc].sort()\n",
    "\n",
    "    # Copy labels to modify safely\n",
    "    new_labels = unlabeled_y.copy()\n",
    "\n",
    "    # Process each location independently\n",
    "    for loc, entries in data_by_location.items():\n",
    "        # Get only the entries currently labeled as class 1\n",
    "        class1_entries = [(s, e, i) for (s, e, i) in entries if unlabeled_y[i] == 1]\n",
    "        class1_entries.sort()\n",
    "\n",
    "        current_sequence = []\n",
    "        for j in range(len(class1_entries)):\n",
    "            s, e, idx = class1_entries[j]\n",
    "            if not current_sequence:\n",
    "                current_sequence.append((s, e, idx))\n",
    "            else:\n",
    "                prev_s, prev_e, _ = current_sequence[-1]\n",
    "                # If current start is close enough to previous end, extend the sequence\n",
    "                if s - prev_e <= time_gap_threshold_us:\n",
    "                    current_sequence.append((s, e, idx))\n",
    "                else:\n",
    "                    # End the current sequence and relabel accordingly\n",
    "                    if len(current_sequence) >= 2:\n",
    "                        for _, _, seq_idx in current_sequence:\n",
    "                            new_labels[seq_idx] = 1  # Keep as class 1\n",
    "                    else:\n",
    "                        for _, _, seq_idx in current_sequence:\n",
    "                            new_labels[seq_idx] = 2  # Reassign to noise\n",
    "                    current_sequence = [(s, e, idx)]\n",
    "\n",
    "        # Process any remaining sequence at the end\n",
    "        if current_sequence:\n",
    "            if len(current_sequence) >= 2:\n",
    "                for _, _, seq_idx in current_sequence:\n",
    "                    new_labels[seq_idx] = 1\n",
    "            else:\n",
    "                for _, _, seq_idx in current_sequence:\n",
    "                    new_labels[seq_idx] = 2\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "# Example usage\n",
    "new_labels = postprocess_class1_sequences(\n",
    "    filtered_unlabeled,         # feature array\n",
    "    final_unlabeled_preds,      # predicted labels (from model)\n",
    "    filtered_meta               # corresponding metadata\n",
    ")\n"
   ],
   "id": "a9027203723c590d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "distribution = Counter(new_labels)\n",
    "total = len(new_labels)\n",
    "print(\"\\nFinal Unlabeled Predictions Distribution:\")\n",
    "for label, count in distribution.items():\n",
    "    pct = (count / total) * 100\n",
    "    print(f\"Class {label}: {count} ({pct:.2f}%)\")"
   ],
   "id": "ab959c1430c45980"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Torch + CUDA)",
   "language": "python",
   "name": "mytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
